# 机器学习概述
1. 在早期的工程领域，机器学习也经常称为模式识别（Pattern Recognition，PR），但模式识别更偏向于具体的应用任务，比如光学字符识别、语音识别、人脸识别.
2. 机器学习的三个基本要素: 模型、学习准则、优化算法．
3. 对于一个机器学习任务，首先要确定其输入空间𝒳和输出空间𝒴，输入空间𝒳和输出空间𝒴构成了一个样本空间。我们希望模型近似真实**映射函数**𝑦 =𝑔(𝒙)或真实条件**概率分布**𝑝𝑟(𝑦|𝒙)。
4. 交叉熵损失函数，多用于分类问题，
5. Hinge损失函数，见之后的svm
6. 期望风险与经验风险，后者是前者在训练集上的局部近似。但是经验风险最小化原则很容易导致模型在训练集上错误率很低，但是在未知数据上错误率很高，也就是过拟合。过拟合问题往往是由于**训练数据少**和**噪声**以及**模型能力强**。因此需要引入正则化限制模型能力，也就是**结构风险最小化**。
7. 可以通过early stop解决过拟合。在每次迭代时，把新得到的模型𝑓(𝒙;𝜃)在验证集上进行测试，并计算错误率．如果在验证集上的错误率不再下降，就停止迭代。

# 线性回归
1. 经验风险最小化
2. 结构风险最小化，岭回归
3. 最大似然估计与最大后验估计，https://blog.csdn.net/u011508640/article/details/72815981
4. 理解上述链接的关键在于，最大后验估计是把参数看成是随机变量，根据贝叶斯定理，求出在目前所已知x的情况下，参数有怎样的概率分布，取概率最大的值，而最大似然估计没有考虑先验知识。单纯将概率看成是参数的函数。
5. 第一项为偏差（Bias），是指一个模型在不同训练集上的平均性能和最优模型的差异，可以用来衡量一个模型的拟合能力．第二项是方差（Variance），是指一个模型在不同训练集上的差异，可以用来衡量一个模型是否容易过拟合，体现泛化能力。
6. 词袋模型是文本的向量表现形式。向量𝒙中第𝑖维的值表示词表中的第𝑖个词是否在𝑥中出现．如果出现，值为1，否则为0。每一个表示为一句话的表示，而不是一个单词的表示。
7. 宏平均与微平均，用于多分类场合，宏平均是每个类别单独建立混淆矩阵(tp,tn等)，类别平均值为宏平均；微平均每个样本部分其标签类别，混在一起计算。